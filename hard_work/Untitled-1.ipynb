{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最优解: [ 0.7597218   0.81693852  0.51618524 -0.85598918 -1.34118632  0.25611217\n",
      " -0.10391063 -1.12190899  0.08417165  0.48249647]\n",
      "最优适应度: 5.617469559206125\n"
     ]
    }
   ],
   "source": [
    "class CMA_ES:\n",
    "    def __init__(self, func, dim, pop_size=50, sigma=0.1, max_iter=1000, tol=1e-6):\n",
    "        self.func = func\n",
    "        self.dim = dim\n",
    "        self.pop_size = pop_size\n",
    "        self.sigma = sigma\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "\n",
    "        # 初始化种群\n",
    "        self.mean = np.random.randn(dim)\n",
    "        self.cov = np.eye(dim)\n",
    "        self.inv_cov = np.linalg.inv(self.cov)\n",
    "        self.best_solution = None\n",
    "        self.best_fitness = float('inf')\n",
    "\n",
    "    def _sample_population(self):\n",
    "        \"\"\"从多元正态分布中生成一个新的种群\"\"\"\n",
    "        return np.random.multivariate_normal(self.mean, self.sigma**2 * self.cov, self.pop_size)\n",
    "\n",
    "    def _update(self, population, fitness):\n",
    "        \"\"\"根据当前种群和适应度更新均值和协方差矩阵\"\"\"\n",
    "        sorted_idx = np.argsort(fitness)\n",
    "        population = population[sorted_idx]\n",
    "        fitness = fitness[sorted_idx]\n",
    "\n",
    "        # 选择最好的半数个体\n",
    "        selected_pop = population[:self.pop_size // 2]\n",
    "\n",
    "        # 更新均值\n",
    "        new_mean = np.mean(selected_pop, axis=0)\n",
    "\n",
    "        # 更新协方差矩阵\n",
    "        z = (selected_pop - new_mean)\n",
    "        new_cov = np.cov(z.T)\n",
    "\n",
    "        return new_mean, new_cov, fitness[0]\n",
    "\n",
    "    def optimize(self):\n",
    "        \"\"\"执行 CMA-ES 优化\"\"\"\n",
    "        for iteration in range(self.max_iter):\n",
    "            # 生成新的种群\n",
    "            population = self._sample_population()\n",
    "            fitness = np.array([self.func(ind) for ind in population])\n",
    "\n",
    "            # 记录最优解\n",
    "            best_idx = np.argmin(fitness)\n",
    "            if fitness[best_idx] < self.best_fitness:\n",
    "                self.best_fitness = fitness[best_idx]\n",
    "                self.best_solution = population[best_idx]\n",
    "\n",
    "            # 如果收敛则提前停止\n",
    "            if self.best_fitness < self.tol:\n",
    "                break\n",
    "\n",
    "            # 更新均值和协方差矩阵\n",
    "            self.mean, self.cov, _ = self._update(population, fitness)\n",
    "\n",
    "        return self.best_solution, self.best_fitness\n",
    "\n",
    "\n",
    "# 测试代码\n",
    "def test_func(x):\n",
    "    \"\"\"目标函数（可以换成任何需要优化的函数）\"\"\"\n",
    "    return np.sum(x**2)  # 简单的平方和\n",
    "\n",
    "# 设置CMA-ES优化器\n",
    "optimizer = CMA_ES(func=test_func, dim=10, pop_size=100, sigma=0.5, max_iter=1000, tol=1e-8)\n",
    "\n",
    "# 执行优化\n",
    "best_solution, best_fitness = optimizer.optimize()\n",
    "\n",
    "print(f\"最优解: {best_solution}\")\n",
    "print(f\"最优适应度: {best_fitness}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5_w,10)-aCMA-ES (mu_w=3.2,w_1=45%) in dimension 10 (seed=813280, Thu Apr  3 15:57:25 2025)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最优解: [-4.66946630e-05  6.64809494e-05  1.14007539e-04  1.88257915e-05\n",
      "  1.17464916e-04  8.21061846e-05 -1.00001221e-04  1.06315998e-04\n",
      " -5.29837798e-05  7.74970416e-05]\n",
      "最优适应度: 7.060807759310412e-08\n"
     ]
    }
   ],
   "source": [
    "import nevergrad as ng\n",
    "import numpy as np\n",
    "\n",
    "# 目标函数（平方和）\n",
    "def test_func(x):\n",
    "    return np.sum(x**2)\n",
    "\n",
    "# 创建优化器\n",
    "optimizer = ng.optimizers.CMA(parametrization=10,budget=1000)  # 设置初始均值和步长，设置优化预算\n",
    "\n",
    "# 使用 CMA-ES 进行优化\n",
    "recommendation = optimizer.minimize(test_func)\n",
    "\n",
    "# 输出最优解\n",
    "print(f\"最优解: {recommendation.value}\")\n",
    "print(f\"最优适应度: {test_func(recommendation.value)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5_w,10)-aCMA-ES (mu_w=3.2,w_1=45%) in dimension 6 (seed=793819, Thu Apr  3 17:06:47 2025)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\69042\\.conda\\envs\\rl1\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 88\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m es\u001b[38;5;241m.\u001b[39mresult\u001b[38;5;241m.\u001b[39mxbest, es\u001b[38;5;241m.\u001b[39mresult\u001b[38;5;241m.\u001b[39mfbest\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# 运行优化\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m best_solution, best_fitness \u001b[38;5;241m=\u001b[39m optimize_with_cma_es()\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimized solution: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_solution\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest fitness value: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_fitness\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[45], line 79\u001b[0m, in \u001b[0;36moptimize_with_cma_es\u001b[1;34m(dimension, popsize, max_iter, max_evals)\u001b[0m\n\u001b[0;32m     77\u001b[0m solutions \u001b[38;5;241m=\u001b[39m es\u001b[38;5;241m.\u001b[39mask()  \u001b[38;5;66;03m# 获取新的候选解\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;66;03m# 对每个候选解进行代理模型评估或实际评估\u001b[39;00m\n\u001b[1;32m---> 79\u001b[0m fitness_values \u001b[38;5;241m=\u001b[39m [surrogate_evaluation(x, surrogate_model, true_objective_function, X_train, y_train) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m solutions]\n\u001b[0;32m     80\u001b[0m es\u001b[38;5;241m.\u001b[39mtell(solutions, fitness_values)  \u001b[38;5;66;03m# 更新CMA-ES的种群\u001b[39;00m\n\u001b[0;32m     81\u001b[0m es\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39madd()  \u001b[38;5;66;03m# 记录优化数据\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[45], line 55\u001b[0m, in \u001b[0;36msurrogate_evaluation\u001b[1;34m(x, surrogate_model, real_evaluation, X_train, y_train)\u001b[0m\n\u001b[0;32m     53\u001b[0m     X_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack([X_train, x])  \u001b[38;5;66;03m# 添加新解\u001b[39;00m\n\u001b[0;32m     54\u001b[0m     y_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(y_train, true_val)  \u001b[38;5;66;03m# 添加真实目标值\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m     surrogate_model\u001b[38;5;241m.\u001b[39mupdate(X_train, y_train)  \u001b[38;5;66;03m# 更新代理模型\u001b[39;00m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m true_val\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[45], line 43\u001b[0m, in \u001b[0;36mSurrogateModel.update\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[1;32m---> 43\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y)\n",
      "Cell \u001b[1;32mIn[45], line 37\u001b[0m, in \u001b[0;36mSurrogateModel.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[1;32m---> 37\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mfit(X, y)\n",
      "File \u001b[1;32mc:\\Users\\69042\\.conda\\envs\\rl1\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\69042\\.conda\\envs\\rl1\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:325\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m iteration \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_restarts_optimizer):\n\u001b[0;32m    323\u001b[0m         theta_initial \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rng\u001b[38;5;241m.\u001b[39muniform(bounds[:, \u001b[38;5;241m0\u001b[39m], bounds[:, \u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    324\u001b[0m         optima\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 325\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constrained_optimization(obj_func, theta_initial, bounds)\n\u001b[0;32m    326\u001b[0m         )\n\u001b[0;32m    327\u001b[0m \u001b[38;5;66;03m# Select result from run with minimal (negative) log-marginal\u001b[39;00m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;66;03m# likelihood\u001b[39;00m\n\u001b[0;32m    329\u001b[0m lml_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(itemgetter(\u001b[38;5;241m1\u001b[39m), optima))\n",
      "File \u001b[1;32mc:\\Users\\69042\\.conda\\envs\\rl1\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:656\u001b[0m, in \u001b[0;36mGaussianProcessRegressor._constrained_optimization\u001b[1;34m(self, obj_func, initial_theta, bounds)\u001b[0m\n\u001b[0;32m    654\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constrained_optimization\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj_func, initial_theta, bounds):\n\u001b[0;32m    655\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfmin_l_bfgs_b\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 656\u001b[0m         opt_res \u001b[38;5;241m=\u001b[39m scipy\u001b[38;5;241m.\u001b[39moptimize\u001b[38;5;241m.\u001b[39mminimize(\n\u001b[0;32m    657\u001b[0m             obj_func,\n\u001b[0;32m    658\u001b[0m             initial_theta,\n\u001b[0;32m    659\u001b[0m             method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL-BFGS-B\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    660\u001b[0m             jac\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    661\u001b[0m             bounds\u001b[38;5;241m=\u001b[39mbounds,\n\u001b[0;32m    662\u001b[0m         )\n\u001b[0;32m    663\u001b[0m         _check_optimize_result(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlbfgs\u001b[39m\u001b[38;5;124m\"\u001b[39m, opt_res)\n\u001b[0;32m    664\u001b[0m         theta_opt, func_min \u001b[38;5;241m=\u001b[39m opt_res\u001b[38;5;241m.\u001b[39mx, opt_res\u001b[38;5;241m.\u001b[39mfun\n",
      "File \u001b[1;32mc:\\Users\\69042\\.conda\\envs\\rl1\\Lib\\site-packages\\scipy\\optimize\\_minimize.py:713\u001b[0m, in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    710\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[0;32m    711\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    712\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 713\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m    714\u001b[0m                            callback\u001b[38;5;241m=\u001b[39mcallback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    715\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    716\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    717\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[1;32mc:\\Users\\69042\\.conda\\envs\\rl1\\Lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:407\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    401\u001b[0m task_str \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFG\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[0;32m    405\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[0;32m    406\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[1;32m--> 407\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m func_and_grad(x)\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_X\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    409\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[0;32m    410\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\69042\\.conda\\envs\\rl1\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:296\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x_impl(x)\n\u001b[1;32m--> 296\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun()\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad()\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[1;32mc:\\Users\\69042\\.conda\\envs\\rl1\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:262\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun_impl()\n\u001b[0;32m    263\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\69042\\.conda\\envs\\rl1\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:163\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[1;32m--> 163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m fun_wrapped(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx)\n",
      "File \u001b[1;32mc:\\Users\\69042\\.conda\\envs\\rl1\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:145\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[1;32m--> 145\u001b[0m fx \u001b[38;5;241m=\u001b[39m fun(np\u001b[38;5;241m.\u001b[39mcopy(x), \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    146\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[1;32mc:\\Users\\69042\\.conda\\envs\\rl1\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:79\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m     78\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[1;32m---> 79\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_if_needed(x, \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[1;32mc:\\Users\\69042\\.conda\\envs\\rl1\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:73\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(x \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m---> 73\u001b[0m     fg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfun(x, \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\69042\\.conda\\envs\\rl1\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:297\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.fit.<locals>.obj_func\u001b[1;34m(theta, eval_gradient)\u001b[0m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobj_func\u001b[39m(theta, eval_gradient\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m eval_gradient:\n\u001b[1;32m--> 297\u001b[0m         lml, grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_marginal_likelihood(\n\u001b[0;32m    298\u001b[0m             theta, eval_gradient\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, clone_kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    299\u001b[0m         )\n\u001b[0;32m    300\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39mlml, \u001b[38;5;241m-\u001b[39mgrad\n\u001b[0;32m    301\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\69042\\.conda\\envs\\rl1\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:587\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.log_marginal_likelihood\u001b[1;34m(self, theta, eval_gradient, clone_kernel)\u001b[0m\n\u001b[0;32m    585\u001b[0m K[np\u001b[38;5;241m.\u001b[39mdiag_indices_from(K)] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha\n\u001b[0;32m    586\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 587\u001b[0m     L \u001b[38;5;241m=\u001b[39m cholesky(K, lower\u001b[38;5;241m=\u001b[39mGPR_CHOLESKY_LOWER, check_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mLinAlgError:\n\u001b[0;32m    589\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf, np\u001b[38;5;241m.\u001b[39mzeros_like(theta)) \u001b[38;5;28;01mif\u001b[39;00m eval_gradient \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf\n",
      "File \u001b[1;32mc:\\Users\\69042\\.conda\\envs\\rl1\\Lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py:44\u001b[0m, in \u001b[0;36mcholesky\u001b[1;34m(a, lower, overwrite_a, check_finite)\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLAPACK reported an illegal value in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m-\u001b[39minfo\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-th argument\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     40\u001b[0m                          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mon entry to \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOTRF\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m c, lower\n\u001b[1;32m---> 44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcholesky\u001b[39m(a, lower\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, overwrite_a\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, check_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m     45\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;124;03m    Compute the Cholesky decomposition of a matrix.\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     86\u001b[0m \n\u001b[0;32m     87\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m     88\u001b[0m     c, lower \u001b[38;5;241m=\u001b[39m _cholesky(a, lower\u001b[38;5;241m=\u001b[39mlower, overwrite_a\u001b[38;5;241m=\u001b[39moverwrite_a, clean\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     89\u001b[0m                          check_finite\u001b[38;5;241m=\u001b[39mcheck_finite)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cma\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def true_objective_function(x):\n",
    "    \"\"\"\n",
    "    复杂目标函数，包含Rastrigin函数、高斯噪声和正弦变化。\n",
    "    :param x: 输入参数，假设是一个N维的向量。\n",
    "    :return: 目标函数值\n",
    "    \"\"\"\n",
    "    # Rastrigin函数的标准形式\n",
    "    A = 10\n",
    "    n = len(x)\n",
    "    rastrigin = A * n + np.sum(x**2 - A * np.cos(2 * np.pi * x))\n",
    "    \n",
    "    # 添加高斯噪声项\n",
    "    # noise = np.random.normal(0, 0.1, 1)  # 均值为0，标准差为0.1的高斯噪声\n",
    "    \n",
    "    # # 添加正弦变化项，增加一些周期性变化\n",
    "    # sine_variation = np.sin(0.5 * np.sum(x)) * 5  # 基于输入向量的和来生成周期性变化\n",
    "    \n",
    "    # 综合计算\n",
    "    return rastrigin #+ noise + sine_variation\n",
    "\n",
    "# 代理模型：高斯过程回归\n",
    "class SurrogateModel:\n",
    "    def __init__(self, kernel=None):\n",
    "        if kernel is None:\n",
    "            # kernel = C(1.0, (1e-4, 1e1)) * RBF(1.0, (1e-4, 1e1))\n",
    "            kernel = C(1.0, (1e-4, 1e10)) * RBF(1.0, (1e-4, 1e1))  # 增大上限\n",
    "        self.model = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X, return_std=True)\n",
    "\n",
    "    def update(self, X, y):\n",
    "        self.fit(X, y)\n",
    "\n",
    "# 代理模型辅助CMA-ES的目标函数评估\n",
    "def surrogate_evaluation(x, surrogate_model, real_evaluation, X_train, y_train):\n",
    "    # 首先使用代理模型进行评估\n",
    "    pred, std = surrogate_model.predict(np.array([x]))\n",
    "    \n",
    "    # 如果代理模型的预测不确定性较大，则使用真实目标函数进行评估\n",
    "    if std > 0.1:  # 可调阈值，决定何时使用真实目标函数\n",
    "        true_val = real_evaluation(x)\n",
    "        X_train = np.vstack([X_train, x])  # 添加新解\n",
    "        y_train = np.append(y_train, true_val)  # 添加真实目标值\n",
    "        surrogate_model.update(X_train, y_train)  # 更新代理模型\n",
    "        return true_val\n",
    "    else:\n",
    "        return pred[0]  # 否则使用代理模型的预测值\n",
    "\n",
    "# 使用CMA-ES进行优化的主函数\n",
    "def optimize_with_cma_es(dimension=6, popsize=10,max_iter=10, max_evals=500):\n",
    "    # CMA-ES的初始配置\n",
    "    es = cma.CMAEvolutionStrategy(np.random.randn(dimension), 0.33, {'popsize': popsize,'maxiter': max_iter, 'maxfevals': max_evals})\n",
    "\n",
    "    # 训练数据初始化\n",
    "    X_train = np.random.uniform(-5, 5, (10, dimension))  # 初始训练数据（随机生成）\n",
    "    y_train = np.array([true_objective_function(x) for x in X_train])  # 真实目标函数值\n",
    "\n",
    "    # 创建代理模型\n",
    "    surrogate_model = SurrogateModel()\n",
    "\n",
    "    # 用初始数据训练代理模型\n",
    "    surrogate_model.fit(X_train, y_train)\n",
    "\n",
    "    # 开始优化\n",
    "    while not es.stop():\n",
    "        solutions = es.ask()  # 获取新的候选解\n",
    "        # 对每个候选解进行代理模型评估或实际评估\n",
    "        fitness_values = [surrogate_evaluation(x, surrogate_model, true_objective_function, X_train, y_train) for x in solutions]\n",
    "        es.tell(solutions, fitness_values)  # 更新CMA-ES的种群\n",
    "        es.logger.add()  # 记录优化数据\n",
    "        print(f\"Best fitness so far: {es.result.fbest}, Best solution: {es.result.xbest}\")\n",
    "        es.disp()  # 显示当前状态\n",
    "\n",
    "    return es.result.xbest, es.result.fbest\n",
    "\n",
    "# 运行优化\n",
    "best_solution, best_fitness = optimize_with_cma_es()\n",
    "print(f\"Optimized solution: {best_solution}\")\n",
    "print(f\"Best fitness value: {best_fitness}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

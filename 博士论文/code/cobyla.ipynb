{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def objective(x):\n",
    "    \"\"\"目标函数：例如最小化 x[0]^2 + x[1]^2\"\"\"\n",
    "    return x[0]**2 + x[1]**2\n",
    "\n",
    "def constraint(x):\n",
    "    \"\"\"约束条件：例如 g(x) = x[0] + x[1] - 1，g(x) >= 0\"\"\"\n",
    "    return x[0] + x[1] - 1\n",
    "\n",
    "def linear_approximation(func, xk, perturbation=1e-5):\n",
    "    \"\"\"线性化函数，通过对目标函数和约束函数进行泰勒展开，估算其梯度\"\"\"\n",
    "    n = len(xk)\n",
    "    approx = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        xk_perturbed = xk.copy()\n",
    "        xk_perturbed[i] += perturbation\n",
    "        approx[i] = (func(xk_perturbed) - func(xk)) / perturbation\n",
    "    return approx\n",
    "\n",
    "def cobyla(objective, constraint, x0, max_iter=100, tol=1e-6, rho=1.0):\n",
    "    \"\"\"COBYLA算法\"\"\"\n",
    "    xk = np.array(x0)  # 当前点\n",
    "    n = len(x0)\n",
    "    m = 1  # 只有一个约束g(x) >= 0\n",
    "    for iteration in range(max_iter):\n",
    "        # 1. 计算目标和约束的线性化\n",
    "        grad_f = linear_approximation(objective, xk)  # 目标函数的梯度\n",
    "        grad_g = linear_approximation(constraint, xk)  # 约束函数的梯度\n",
    "        f_xk = objective(xk)\n",
    "        g_xk = constraint(xk)\n",
    "        \n",
    "        # 2. 构建单纯形\n",
    "        simplex = np.array([xk + np.random.randn(n) * rho for _ in range(n+1)])\n",
    "        \n",
    "        # 3. 线性拟合：目标函数和约束的近似\n",
    "        a0 = grad_f\n",
    "        b0 = f_xk\n",
    "        ag = grad_g\n",
    "        bg = g_xk\n",
    "        \n",
    "        # 4. 解线性优化子问题\n",
    "        # 在信赖域内最小化线性近似模型，目标是最小化 a0^T d\n",
    "        # 线性约束为 ag^T d + bg >= 0, 并且 ||d|| <= rho\n",
    "        d = np.linalg.solve(np.outer(a0, a0) + np.outer(ag, ag), -a0)\n",
    "        \n",
    "        # 5. 更新点和信赖域\n",
    "        xk_next = xk + d\n",
    "        if objective(xk_next) < f_xk:\n",
    "            xk = xk_next\n",
    "            rho *= 1.2  # 扩大信赖域\n",
    "        else:\n",
    "            rho *= 0.5  # 缩小信赖域\n",
    "        \n",
    "        # 6. 收敛判断\n",
    "        if np.linalg.norm(d) < tol:\n",
    "            print(f\"Converged at iteration {iteration}\")\n",
    "            break\n",
    "\n",
    "    return xk\n",
    "\n",
    "# 初始点\n",
    "x0 = [0.5, 0.5]\n",
    "result = cobyla(objective, constraint, x0)\n",
    "print(f\"Optimization result: {result}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
